## 大文件上传

* 将大文件转换成 二进制流的格式
* 利用流可以切割的属性，将二进制流切割成多份
* 组装和分割块同等数量的请求块，并行或串行的形式发出请求（串行要比并行要快）
* 待我们监听到所有请求都成功发出去以后，再给服务端发出一个合并的信号 (merge) 合并请求

### 断点续传
* 为每一个文件切割块添加不同的标识
* 当上传成功的之后，记录上传成功的标识
* 当我们暂停或者发送失败后，可以重新发送没有上传成功的切割文件

### 服务器端
* 接收每一个切割文件，并在接收成功后，存到指定位置，并告诉前端接收成功
* 收到合并信号，将所有的切割文件排序，合并，生成最终的大文件，然后删除切割小文件，并告知前端大文件的地址
* 返回前端合并后 大文件的地址

#### 将文件变成二进制，方便后续的分片续传

js常见的二进制格式有 Blob,ArrayBuffer 和 Buffer，这里没有采用其他文章常用的Blob，而是采用了ArrayBuffer

```js
filepParse(file, type) {
  const caseType = {
    'base64': 'readAsDataURL',
    'buffer': 'readAsArrayBuffer'
  }
  const fileRead = new FileReader()
  return new Promise(resolve => {
    fileRead[caseType[type]](file)
    fileRead.onload = (res) => {
      resolve(res.target.result)
    }
  })
}
```

#### 将文件进行分片的操作

在我们拿到具体的二进制流之后我们就可以进行分块了，就像操作数组一样方便。
当然了，我们在拆分切片大文件的时候，还要考虑大文件的合并，所以我们的拆分必须有规律，
比如 1-1，1-2，1-3 ，1-5 这样的，到时候服务端拿到切片数据，当接收到合并信号当时候，就可以将这些切片排序合并了。
同时，我们为了避免同一个文件（改名字）多次上传，我们引入了 spark-md5 ，根据具体文件内容，生成hash值 (uuid 感觉也可以)

```js
const buffer = await this.filepParse(file,'buffer')
      
const sparkMD5 = new SparkMD5.ArrayBuffer()

sparkMD5.append(buffer)
this.hash = sparkMD5.end()
```

而我们，为每一个切片命名当时候，也改成了 hash-1，hash-2 这种形式，

我们分割大文件的时候，可以采用 定切片数量，定切片大小，两种方式，我们这里采用了 定切片数量这个简单的方式做例子

```js
const partSize = file.size / 10
let current = 0

 for (let i = 0 ;i < 10 ;i++) {
   let reqItem = {
     chunk: file.slice(current, current + partSize),
     filename: `${this.hash}_${i}.${suffix}`
   }
   current += partSize
   partList.push(reqItem)
 }
 this.partList = partList
```

固定分割成10份


### 创建请求
这里需要注意的就是，我们发出去的数据采用的是FormData数据格式

```js
function createSendQeq() {
    const reqPartList = []
    this.partList.forEach((item,index) => {
      const reqFn = () => {
        const formData = new FormData();
        formData.append("chunk", item.chunk);
        formData.append("filename", item.filename);
        return axios.post("/upload",formData,{
          headers: {"Content-Type": "multipart/form-data"}
        }).then(res => {
          console.log(res)
        })
      }
      reqPartList.push(reqFn)
    })
    return reqPartList
}
```

#### 将每一个切片 并行/串行 的方式发出

目前切片已经分好了，并且我们的请求也已经包装好了。 目前我们有两个方案 并行/串行 因为串行容易理解

我们每成功的发出去一个请求，那么我们对应的下标就加一，证明我们的发送成功。当 i 下标和 我们的切片数相同的时候，我们默认发送成功，触发 合并（merge）

```js
function sendAndMerge() {
 const reqPartList = this.createSendQeq()
  let i  = 0 
  let send = async () => {
    if (i >= reqPartList.length) { 
      // 上传完成
      this.mergeUpload()
      return 
    }
    await reqPartList[i]()
    i++
    send()
  }
  send()
  
}
```

### 断点续传代码部分
理解了前面的思路，这一部分的代码也容易得到思路 点击暂停的时候，停止上传。点击继续上传的话，我们继续上传剩下的请求，所以，我们对上传成功的请求要做处理

```js
if (res.data.code === 0) {
    this.count += 1;
    // 传完的切片我们把它移除掉
    this.partList.splice(index, 1); // 这里可以merge的时候整个文件删掉,不过考虑到断点续传 所以需要一个个删除
}
```

如果上传成功，我们就将其从请求数组中剥离出去，这样我们就可以保证剩下的，就是待上传的了，断点续传的核心




